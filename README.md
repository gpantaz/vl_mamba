# Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision \& Language Modeling (EMNLP 2024)
[[Paper](https://arxiv.org/pdf/2409.05395)][[Model Checkpoints](#model-checkpoints)][[Data](#data)][[Training](#training)]

## Requirements

## Model Checkpoints

## Data

## Training

### Pretraining

### Instruction-tuning

### Training logs

All the logs regarding pretraining / finetuning can be found on [wandb](https://wandb.ai/gpantaz/vl_mamba?nw=nwusergpantaz)
Note that some of the runs were resumed from a previous checkpoint.
